{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to plotAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotar\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First get the Iris data from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_IRIS_ - the hello-world of statistics - consists of 150 samples in 3 species (in `iris.target`) and the features are dimensions of the indivicual blooms (`sepal/petal` `length/width`).\n",
    "\n",
    "We plot the first three features and give the species as colors (and give the Plot a name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.plotar(iris.data, iris.target, name='iris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wrote the plot to the server - how does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just scan the QR-Code with your mobile device and open the URL - this will open this in your browser. Tap on the the **AR-Icon** in the Modelview to step in the Augmented Reality or take the link **Open in VR** to your VR googles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can save the plot in it's JSON-format or in a rendered 3D format (glTF for Android, USDZ for iOS/macOS, any of those for Blender):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write(\"examples/iris.json\", format=\"json\")\n",
    "plot.write(\"examples/iris.gltf\", format=\"gltf\")\n",
    "plot.write(\"examples/iris.usdz\", format=\"usdz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What should happen here is, that your mobile device connects to this very Jupyter server! For that to work plotar tries to guess a URL that also works from you mobile: ![Architecture](images/architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Troubleshooting**: If you cannot connect to this server consider the following steps:\n",
    "* Enable connections from outside by (re-)starting Jupyter: `jupyter lab --ip=\"*\"`\n",
    "* Try to have your mobile device to be on the same network as your desktop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING** Jupyter is secured by default to have a non-guessable token to get some level of security, but still you probably do not use HTTPS, so anybody intercepting the traffic between you mobile device and your desktop can see all your data! This might be ok in your home network or in a company enterprise - be cautious!\n",
    "\n",
    "Traffic with mybinder.org actually is secured by HTTPS and the token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAPminder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now take the GAPminder data: development indicators for all countries in the world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the Plotly-Version that has only data for years 1952 to 2007:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/plotly/datasets/master/gapminderDataFiveYear.csv'\n",
    "gap = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep it visible let's take only the European countries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotar.linear(gap.query(\"continent=='Europe'\"), xyz=['gdpPercap','year','lifeExp'],\n",
    "              col='country', size='pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write(\"examples/gapminder.json\", format=\"json gltf glb usda usdz\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAPminder animated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's animate it like in Hans Rosling's famours [Lecture](https://www.youtube.com/watch?v=jbkSRLYSojo) showing how world wars etc. and general development shaped countries by looking at ther income per capita, life expectancy and population as size  - however we can use one more dimension! children_per_woman are available for the whole time period.\n",
    "\n",
    "For this we actually want to have more historic data - thanks to University of Toronto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/UofTCoders/2018-09-10-utoronto/raw/gh-pages/data/world-data-gapminder.csv'\n",
    "gap = pd.read_csv(url)\n",
    "gap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = plotar.animate(gap.query(\"region=='Europe'\"), xyz=['income','children_per_woman','life_expectancy'],\n",
    "    group='country', col='sub_region', size='population', animation_frame='year',\n",
    "    name=\"gapminder-animated\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The spheres are nice, however we don't know which dot is which country - so take the country name directly to the plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write(\"examples/gapminder-animated.json\", format=\"json gltf glb usda usdz\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.animate(gap.query(\"region=='Europe'\"), xyz=['income','children_per_woman','life_expectancy'],\n",
    "    group='country', col='sub_region', size='population', animation_frame='year',\n",
    "    label = 'country', name=\"gapminder-animated-label\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write(\"examples/gapminder-animated-label.json\", format=\"json gltf glb usda usdz\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D ONE Team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scrape the http://d-one.ai/team webpage and extract some features on the team member's description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://d-one.ai/team'\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "x = soup.find_all(\"div\", class_=\"details\")\n",
    "team = pd.DataFrame( dict(name=_.find_all('h3')[0].text, text=_.find_all('p')[0].text) for _ in x )\n",
    "team = team.drop_duplicates('name')\n",
    "team"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract two approximate counts: number of words and number of sentence (the latter actuall fails e.g. if many Abbreviations are used :-| )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team['n_sent'] = team.text.str.replace(r'[^.]','', regex=True).str.len()\n",
    "team['n_word'] = team.text.str.replace(r'[^ ]','', regex=True).str.len()+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the last mentioned year - usually that is, when people started. If we do not find one, take 2000 as a default value - that is before the company was founded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = team.text.apply(lambda x: ([2000] + [_ for _ in x.split() if _.startswith(\"20\")])[-1])\n",
    "team['year_start'] = years.astype(str).str.rstrip('.').astype(int)\n",
    "team['year_start'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team['dr'] = team.name.str.startswith(\"Dr.\")\n",
    "team['dr'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.plotar(team, xyz=['n_word', 'n_sent', 'year_start'], col='dr', label='name', size=0.2)\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH - surface of Switzerland"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [Swisstopo Digital Height Model](https://www.swisstopo.admin.ch/de/geodata/height/dhm25200.html) 200m grid to draw a surface of Swizterland."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.geo.admin.ch/ch.swisstopo.digitales-hoehenmodell_25/data.zip'\n",
    "file_name = 'DHM200.asc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download Zip file, unzip the part we need to file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_download(url, file_name, cache=\"tmp\"):\n",
    "    file = Path(cache) / file_name\n",
    "    if not file.exists():\n",
    "        from io import BytesIO\n",
    "        from zipfile import ZipFile\n",
    "        import shutil\n",
    "        print(f\"Downloading {url} to {file} ...\")\n",
    "        zipfile = ZipFile(BytesIO(requests.get(url).content))\n",
    "        with open(file, 'wb') as f:\n",
    "            shutil.copyfileobj(zipfile.open(file_name), f)\n",
    "        print(f\"Downloaded {file} from {url}\")\n",
    "    else:\n",
    "        print(f\"getting {file} from cache\")\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = get_or_download(url, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GeoSpatial Information is in the first 6 rows of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_head = {k: float(v) for k,v in np.genfromtxt(file, dtype=str, max_rows=6)}\n",
    "print(y_head)\n",
    "y = np.genfromtxt(file, skip_header=6, skip_footer=1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n,m = [int(y_head[_]) for _ in ['NCOLS','NROWS']]\n",
    "n,m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = y.flatten()[:n*(m-1)].reshape((m-1,n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is actually rather big - if you want you can make it smaller by setting factor to e.g. 5, 10, 20. We set it to 2 for mybinder.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factor = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img[::factor,::factor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xvec = np.arange(img.shape[1]) * y_head['CELLSIZE'] * factor\n",
    "yvec = np.arange(img.shape[0]) * y_head['CELLSIZE'] * factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impute negative, i.e. NA values to some level below switerlands elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[img>0].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[img<0] = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quickly draw it here so we understand whats happening:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img, interpolation='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually - since the Swiss geographical coordinate system (LV95) is in meters (our xvec and yvec), and the height is as well - this is in all our export formats a correct scale representation of the surface of switerzland!\n",
    "\n",
    "In the plots obviously it will be shown on a much smaller scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = plotar.surfacevr(img, x=xvec, y=yvec, auto_scale=False, name=\"CH\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CH-color - surface of Switzerland with color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add the official satellite image on top of that surface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_file = get_or_download(\"https://data.geo.admin.ch/ch.swisstopo.images-landsat25/data.zip\", \"LandsatMos25.tif\")\n",
    "landsat_metadata_file = get_or_download(\"https://data.geo.admin.ch/ch.swisstopo.images-landsat25/data.zip\", \"Landsatmos25.TFW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_head = np.genfromtxt(landsat_metadata_file).astype(np.int64)\n",
    "sat_head.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description [[Source](http://www.omg.unb.ca/~jonnyb/processing/geotiff_tifw_format.html)]:\n",
    "* First row is x-pixel resolution\n",
    "* Second and third rows are so-called \"rotational components\" but are set to zero in the case of an unrotated mapsheet.\n",
    "* The fourth row is the y-pixel resolution. The negative sign indicates that the image y-axis is positive down which is the opposite from real world coordinates.\n",
    "* The 5th and 6th rows are the Easting and Northing of the upper left pixel (0,0 in image coordinates). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you compare `y_head` and `sat_head` you see that unfortunately we need to crop the satellite to match the frame of the surface data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = (\n",
    "    -sat_head[4] + (y_head['XLLCORNER']),\n",
    "    sat_head[5] - (y_head['YLLCORNER'] + y_head['CELLSIZE'] * y_head['NROWS']),\n",
    ")\n",
    "crop = crop + (\n",
    "    crop[0] + y_head['CELLSIZE'] * y_head['NCOLS'],\n",
    "    crop[1] + y_head['CELLSIZE'] * y_head['NROWS'],\n",
    ")\n",
    "np.array(crop)/25.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat = Image.open(landsat_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No crop it and rescale it to the size of the surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_small = landsat.crop(np.array(crop)/25.0).resize(reversed(img.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_small.size, np.array(landsat_small).shape, img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No plot it and resize it - also exaggerate the height by a factor ~3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot = plotar.surfacevr(img/100000, x=xvec/300000, y=yvec/300000, surfacecolor=np.array(landsat_small).astype(int).tolist(),\n",
    "                             auto_scale=False, name=\"CH-color\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write(\"examples/CH-color.json\", format=\"json gltf glb usda usdz\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize the position of the Planets in the solar system at some time using the skyfield package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield.api import Loader\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load = Loader(\"./tmp/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = load.timescale()\n",
    "t = ts.utc(2022, 5, 22, 15, 19)\n",
    "tarr = ts.utc(2022, 5, range(-365,365, 14))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** on mybinder.org unfortunately ftp-downloads are blocked so this will run into a timeout. We are preparing a workaround."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets = load('de421.bsp')  # ephemeris DE421"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_names = [ _[-1] for i,_ in planets.names().items() if 0 < i < 100 ]\n",
    "print(len(planet_names))\n",
    "planet_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Planet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = \"\"\"i\tName\tEquatorial diameter [i]\tMass [i]\tSemi-major axis (AU)\tOrbital period (years)\tInclination to Sun's equator (°)\tOrbital eccentricity\tRotation period (days)\tConfirmed moons\tAxial tilt (°)\tRings\tAtmosphere\n",
    "1.\tMercury\t0.383\t0.06\t0.39\t0.24\t3.38\t0.206\t58.65\t0\t0.10\tno\tminimal\n",
    "2.\tVenus\t0.949\t0.81\t0.72\t0.62\t3.86\t0.007\t−243.02\t0\t177.30\tno\tCO2, N2\n",
    "3.\tEarth\t1.000\t1.00\t1.00\t1.00\t7.25\t0.017\t1.00\t1\t23.44\tno\tN2, O2, Ar\n",
    "4.\tMars\t0.532\t0.11\t1.52\t1.88\t5.65\t0.093\t1.03\t2\t25.19\tno\tCO2, N2, Ar\n",
    "5.\tJupiter\t11.209\t317.83\t5.20\t11.86\t6.09\t0.048\t0.41\t79\t3.12\tyes\tH2, He\n",
    "6.\tSaturn\t9.449\t95.16\t9.54\t29.45\t5.51\t0.054\t0.44\t82\t26.73\tyes\tH2, He\n",
    "7.\tUranus\t4.007\t14.54\t19.19\t84.02\t6.48\t0.047\t−0.72\t27\t97.86\tyes\tH2, He, CH4\n",
    "8.\tNeptune\t3.883\t17.15\t30.07\t164.79\t6.43\t0.009\t0.67\t14\t29.60\tyes\tH2, He, CH4j\"\"\"\n",
    "planet_info = pd.read_csv(io.StringIO(_), delimiter='\\t').drop(columns=['i']).set_index(\"Name\")\n",
    "planet_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planet_info['Equatorial diameter [i]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets_traj_xyz = pd.concat([\n",
    "    pd.DataFrame(planets[_].at(tarr).ecliptic_xyz().au.T, columns=list('xyz'))\n",
    "    .assign(planet=_).assign(t=tarr.tt.astype(int))\n",
    "    for _ in planet_names\n",
    "])\n",
    "planets_traj_xyz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%debug\n",
    "plot = plotar.animate(planets_traj_xyz, xyz=['x','y','z'],\n",
    "              group='planet', col='planet', size=planet_info['Equatorial diameter [i]'].to_list()+[1,1],\n",
    "              animation_frame='t', name='planets')\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write(\"examples/planets.json\", format=\"json gltf glb usda usdz\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skyfield.api import N, W, wgs84, load\n",
    "from skyfield.functions import length_of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.flightradar24.com/flights/most-tracked'\n",
    "# flightradar24 refuses 'User-Agent': 'python-requests/2.25.1' with error 451 Unavailable For Legal Reasons\n",
    "res = requests.get(url, headers={'User-Agent': ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_tracked = pd.DataFrame(res.json()['data'])\n",
    "most_tracked['name'] = most_tracked.fillna('_').apply(\n",
    "    lambda _: f\"{_.callsign} {_.from_city}->{_.to_city}\", axis=1)\n",
    "most_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flight(flight_id, name):\n",
    "    url = f'https://data-live.flightradar24.com/clickhandler/?version=1.5&flight={flight_id}'\n",
    "    res = requests.get(url)\n",
    "    trail = pd.DataFrame(res.json()['trail'])\n",
    "    trail['flight_id'] = flight_id\n",
    "#     trail['name'] = name\n",
    "    return trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flights = pd.concat(( get_flight(_.flight_id, _.name) for _ in most_tracked.itertuples()), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trail = most_tracked.merge(flights, on=\"flight_id\")\n",
    "trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = trail.apply(lambda _: wgs84.latlon(_.lat, _.lng, _.alt*10).at(t).position.m, axis=1)\n",
    "trail[['x','y','z']] = np.stack(_) / 1000\n",
    "trail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.linear(trail, xyz=['x','y','z'], col='name', size=trail.spd/10, auto_scale=True, type='l', name='flights')\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lorenz Attractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rho = 28.0\n",
    "sigma = 10.0\n",
    "beta = 8.0 / 3.0\n",
    "\n",
    "def f(state, t):\n",
    "    x, y, z = state  # Unpack the state vector\n",
    "    return sigma * (y - x), x * (rho - z) - y, x * y - beta * z  # Derivatives\n",
    "\n",
    "state0 = np.array([1.0, 1.0, 1.0])\n",
    "t = np.arange(0.0, 40.0, 0.01)\n",
    "\n",
    "states = odeint(f, state0, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.linear(states, auto_scale=True, type='l', name=\"lorenz\")\n",
    "plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.write(\"examples/lorenz.json\", format=\"json gltf glb usda usdz\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOLA 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Sola 2022](https://trackmaxx.ch/maps/?m=ec368d93-aff4-4a7e-b0a5-24b7f9683a32&style=swisstopo&legend=full&tracks=1,2,3,4,5,6,8,7,9,10,11,12,13,14,20&labels=iconsubergabebuchlern,iconsuebergaben,icstrecke10,icstrecke11,icstrecke14,icstrecke2,icstrecke3,icstrecke4,icstrecke5,icstrecke6,icstrecke7,icstrecke8,icugbucheggplatz,icstrecke9,icugegg,icugfelsenegg,icugfluntern,icugforch,icughoenggerberg,icugirchel,icuguetliberg,icugwitikon,icugzumikon&h=8d68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://tmxx-static.s3.amazonaws.com/ous/asvzsolazh/mapstudio/gpx/strecke01.gpx\"\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"max_colwidth\", 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(res.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sola_track(strecke):\n",
    "    url = f\"https://tmxx-static.s3.amazonaws.com/ous/asvzsolazh/mapstudio/gpx/strecke{strecke:02}.gpx\"\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    x = soup.find_all(\"trkpt\")\n",
    "    track = pd.DataFrame( _.attrs for _ in x )\n",
    "    track['ele'] = pd.Series( _.ele.text for _ in x)\n",
    "    track = track.astype(float)\n",
    "    track['strecke'] = strecke\n",
    "    return track\n",
    "sola_track(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sola = pd.concat( (sola_track(_) for _ in range(1,15)), axis=0)\n",
    "sola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sola.plot.line('lon','lat',);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = plotar.linear(sola, xyz=['lon','lat','ele'], col=sola.strecke.astype(str), auto_scale=True, type='l', name=\"sola\")\n",
    "plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
